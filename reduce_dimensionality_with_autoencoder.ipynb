{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "reduce dimensionality with autoencoder.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "1nRezmzlns-z"
      },
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "import math\n",
        "from scipy.io import loadmat"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tCWqseajotj8"
      },
      "source": [
        "data pre-proccessing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "blIs3phOn5JB"
      },
      "source": [
        "file = loadmat('/content/drive/MyDrive/spike_data.mat')\n",
        "data = file['wf']\n",
        "data_concat = data[0][0]\n",
        "for i in range(0, 96):\n",
        "  for j in range(0, 5):\n",
        "    if not(i==0 and j==0):\n",
        "      data_concat = np.append(data_concat, data[i][j], axis=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O5qrSCMMn6Pb"
      },
      "source": [
        "def pca(data, dim=2):\n",
        "    m = tf.cast(data.shape[0], dtype='float32')                             # number of data\n",
        "    data_new = data - tf.reduce_mean(data, axis=0, keepdims=True)           # 1.centralize data\n",
        "    # data_new = data_new/tf.math.reduce_variance(data, axis=1, keepdims=True)\n",
        "    cov_matrix = tf.matmul(data_new, data_new, transpose_a=True)/(m - 1)    # 2.compute cov matrix\n",
        "    e, v = tf.linalg.eigh(cov_matrix)                                       # 3.eigen decomposition\n",
        "    e_indices = tf.math.top_k(e, k=dim)[1]                                  # 4-1.pick indices of the max 2 eigenvalues\n",
        "    v_new = tf.gather(v, indices=e_indices)                                 # 4-2.choose corresponding eigenvectors\n",
        "    data_dim_reduced = tf.matmul(v_new, data_new, transpose_b=True)         # 5.reduce dimension\n",
        "    return data_dim_reduced"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_BMi9SPjooAE"
      },
      "source": [
        "plot all data points with dimensionality reduced:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4nBJTx44oFNp"
      },
      "source": [
        "fig = plt.figure(figsize=(15,15))\n",
        "ax1 = fig.add_subplot(111)\n",
        "ax1.set_title('reduce dimension by PCA')\n",
        "plt.xlabel('X')\n",
        "plt.ylabel('Y')\n",
        "plt.xlim((-1200,1200))\n",
        "plt.ylim((-300,1800))\n",
        "x_ticks = np.arange(-1200, 1200, 100)\n",
        "y_ticks = np.arange(-300, 1800, 50)\n",
        "plt.xticks(x_ticks)\n",
        "plt.yticks(y_ticks)\n",
        "\n",
        "data_dim_reduced = pca(data_concat)\n",
        "x = data_dim_reduced[0,:]\n",
        "y = data_dim_reduced[1,:]\n",
        "ax1.scatter(x, y, c = 'b', marker = '.')\n",
        "ax1.plot(x, 3*x)\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6vrTmSc7okxf"
      },
      "source": [
        "plot three clusters:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W0Kzf7QWoHmm"
      },
      "source": [
        "data_dim_reduced = np.array(data_dim_reduced)\n",
        "\n",
        "a, b, c = [], [], []\n",
        "orig_a, orig_b, orig_c = [], [], []\n",
        "for i in np.where(data_dim_reduced[1,:] > 200)[0]:\n",
        "  x_value = data_dim_reduced[0][i]\n",
        "  y_value = data_dim_reduced[1][i]\n",
        "  above_line = 3 * x_value\n",
        "  if x_value < -100:\n",
        "    a.append([x_value, y_value])\n",
        "    orig_a.append(data_concat[:,i])\n",
        "  elif x_value > -100 and y_value > above_line:\n",
        "    b.append([x_value, y_value])\n",
        "    orig_b.append(data_concat[:,i])\n",
        "  elif y_value < above_line:\n",
        "    c.append([x_value, y_value])\n",
        "    orig_c.append(data_concat[:,i])\n",
        "\n",
        "cluster_a = np.array(a)\n",
        "cluster_b = np.array(b)\n",
        "cluster_c = np.array(c)\n",
        "\n",
        "cluster_orig_a = np.array(orig_a)\n",
        "cluster_orig_b = np.array(orig_b)\n",
        "cluster_orig_c = np.array(orig_c)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DMJBfEmioMQi"
      },
      "source": [
        "fig = plt.figure(figsize=(5,5))\n",
        "ax1 = fig.add_subplot(111)\n",
        "plt.xlabel('X')\n",
        "plt.ylabel('Y')\n",
        "plt.xlim((-1200,1200))\n",
        "plt.ylim((-300,1800))\n",
        "\n",
        "x_a = cluster_a[:,0]\n",
        "y_a = cluster_a[:,1]\n",
        "\n",
        "x_b = cluster_b[:,0]\n",
        "y_b = cluster_b[:,1]\n",
        "\n",
        "x_c = cluster_c[:,0]\n",
        "y_c = cluster_c[:,1]\n",
        "\n",
        "ax1.scatter(x_a, y_a, c = 'r', marker = '.')\n",
        "ax1.scatter(x_b, y_b, c = 'b', marker = '.')\n",
        "ax1.scatter(x_c, y_c, c = 'g', marker = '.')\n",
        "\n",
        "plt.show()\n",
        "\n",
        "fig2 = plt.figure(figsize=(12,12))\n",
        "ax1 = fig2.add_subplot(311)\n",
        "ax2 = fig2.add_subplot(312)\n",
        "ax3 = fig2.add_subplot(313)\n",
        "plt.xlabel('t')\n",
        "plt.ylabel('haha')\n",
        "plt.xlim((0,64))\n",
        "plt.ylim((-200,200))\n",
        "\n",
        "x = np.arange(64)\n",
        "\n",
        "# cluster a\n",
        "for i in range(cluster_orig_a.shape[0]):\n",
        "  ax1.plot(x, cluster_orig_a[i], c = 'r', marker = '.')\n",
        "\n",
        "# cluster b\n",
        "for i in range(cluster_orig_b.shape[0]):\n",
        "  ax2.plot(x, cluster_orig_b[i], c = 'b', marker = '.')\n",
        "\n",
        "# cluster c\n",
        "for i in range(cluster_orig_c.shape[0]):\n",
        "  ax3.plot(x, cluster_orig_c[i], c = 'g', marker = '.')\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SYfO0MVfoM-L"
      },
      "source": [
        "fig3 = plt.figure(figsize=(30,10))\n",
        "ax1 = fig3.add_subplot(111)\n",
        "plt.xlabel('t')\n",
        "plt.ylabel('haha')\n",
        "plt.xlim((0,64))\n",
        "plt.ylim((-200,200))\n",
        "\n",
        "x = np.arange(64)\n",
        "\n",
        "for i in range(1900):\n",
        "  ax1.plot(x, data_concat[:,i], c = 'r', marker = '.')\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}